{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.applications import ResNet50,ResNet101\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image3476.jpg</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image5198.jpg</td>\n",
       "      <td>Candle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image4183.jpg</td>\n",
       "      <td>Snowman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image1806.jpg</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image7831.jpg</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image          Class\n",
       "0  image3476.jpg  Miscellaneous\n",
       "1  image5198.jpg         Candle\n",
       "2  image4183.jpg        Snowman\n",
       "3  image1806.jpg  Miscellaneous\n",
       "4  image7831.jpg  Miscellaneous"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/hackerearth-deep-learning-challenge-holidayseason/dataset/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we are going to divide dataset\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the size of dataset without disturbing their corresponding ratios \n",
    "\n",
    "Misce = train[train[\"Class\"]=='Miscellaneous']\n",
    "Chris_tree = train[train[\"Class\"]=='Christmas_Tree']\n",
    "Jacket = train[train[\"Class\"]=='Jacket']\n",
    "Candle = train[train[\"Class\"]=='Candle']\n",
    "Airplane = train[train[\"Class\"]=='Airplane']\n",
    "Snowman = train[train[\"Class\"]=='Snowman']\n",
    "\n",
    "df = pd.concat([df,Misce])\n",
    "df = pd.concat([df,Chris_tree])\n",
    "df = pd.concat([df,Jacket])\n",
    "df = pd.concat([df,Candle])\n",
    "df = pd.concat([df,Airplane])\n",
    "df = pd.concat([df,Snowman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12938, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Path For Images Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../input/hackerearth-deep-learning-challenge-holidayseason/dataset/train'\n",
    "TEST_PATH = '../input/hackerearth-deep-learning-challenge-holidayseason/dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(IMG_SIZE):\n",
    "    base_model =applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    add_model = Sequential()\n",
    "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    add_model.add(Dropout(0.3))\n",
    "    add_model.add(Dense(64, activation='relu'))\n",
    "    add_model.add(Dropout(0.4))\n",
    "\n",
    "    add_model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the average of all predictions\n",
    "\n",
    "main_pred = []\n",
    "data_kfold = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X, Y for training \n",
    "\n",
    "train_y = df.Class\n",
    "train_x = df.drop(['Class'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I took 7 splits as we have 6 labels and even for worst case at least 1 label will have 2 occurence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase EPOCHS variable if you are going for competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "N_SPLIT = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training And Predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11089 validated image filenames belonging to 6 classes.\n",
      "Found 1849 validated image filenames belonging to 6 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "346/346 [==============================] - 182s 506ms/step - loss: 1.6755 - accuracy: 0.4604 - val_loss: 2.7509 - val_accuracy: 0.0952\n",
      "Epoch 2/10\n",
      "346/346 [==============================] - 146s 422ms/step - loss: 0.9309 - accuracy: 0.6544 - val_loss: 0.9683 - val_accuracy: 0.6360\n",
      "Epoch 3/10\n",
      "346/346 [==============================] - 145s 419ms/step - loss: 0.8207 - accuracy: 0.7037 - val_loss: 0.4603 - val_accuracy: 0.8388\n",
      "Epoch 4/10\n",
      "346/346 [==============================] - 145s 420ms/step - loss: 0.7276 - accuracy: 0.7368 - val_loss: 0.3820 - val_accuracy: 0.8615\n",
      "Epoch 5/10\n",
      "346/346 [==============================] - 145s 419ms/step - loss: 0.6588 - accuracy: 0.7638 - val_loss: 0.3767 - val_accuracy: 0.8561\n",
      "Epoch 6/10\n",
      "346/346 [==============================] - 146s 420ms/step - loss: 0.6423 - accuracy: 0.7683 - val_loss: 0.3422 - val_accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "346/346 [==============================] - 145s 419ms/step - loss: 0.5583 - accuracy: 0.7984 - val_loss: 0.3143 - val_accuracy: 0.8843\n",
      "Epoch 8/10\n",
      "346/346 [==============================] - 145s 419ms/step - loss: 0.5347 - accuracy: 0.8090 - val_loss: 0.2906 - val_accuracy: 0.8951\n",
      "Epoch 9/10\n",
      "346/346 [==============================] - 144s 417ms/step - loss: 0.4809 - accuracy: 0.8255 - val_loss: 0.2772 - val_accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "346/346 [==============================] - 145s 418ms/step - loss: 0.4831 - accuracy: 0.8250 - val_loss: 0.2607 - val_accuracy: 0.8999\n",
      "Found 11089 validated image filenames belonging to 6 classes.\n",
      "Found 1849 validated image filenames belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "346/346 [==============================] - 151s 425ms/step - loss: 1.7594 - accuracy: 0.4316 - val_loss: 2.3825 - val_accuracy: 0.2904\n",
      "Epoch 2/10\n",
      "346/346 [==============================] - 145s 418ms/step - loss: 1.0149 - accuracy: 0.6203 - val_loss: 1.3026 - val_accuracy: 0.5608\n",
      "Epoch 3/10\n",
      "346/346 [==============================] - 145s 418ms/step - loss: 0.8229 - accuracy: 0.6877 - val_loss: 0.4964 - val_accuracy: 0.8140\n",
      "Epoch 4/10\n",
      "346/346 [==============================] - 144s 417ms/step - loss: 0.7619 - accuracy: 0.7157 - val_loss: 0.4674 - val_accuracy: 0.8259\n",
      "Epoch 5/10\n",
      "346/346 [==============================] - 145s 418ms/step - loss: 0.6672 - accuracy: 0.7589 - val_loss: 0.4200 - val_accuracy: 0.8540\n",
      "Epoch 6/10\n",
      "346/346 [==============================] - 144s 417ms/step - loss: 0.6284 - accuracy: 0.7662 - val_loss: 0.3774 - val_accuracy: 0.8659\n",
      "Epoch 7/10\n",
      "346/346 [==============================] - 145s 418ms/step - loss: 0.5865 - accuracy: 0.7903 - val_loss: 0.3648 - val_accuracy: 0.8621\n",
      "Epoch 8/10\n",
      "346/346 [==============================] - 144s 416ms/step - loss: 0.5435 - accuracy: 0.8036 - val_loss: 0.3235 - val_accuracy: 0.8810\n",
      "Epoch 9/10\n",
      "346/346 [==============================] - 144s 417ms/step - loss: 0.5049 - accuracy: 0.8150 - val_loss: 0.3145 - val_accuracy: 0.8794\n",
      "Epoch 10/10\n",
      "346/346 [==============================] - 144s 417ms/step - loss: 0.4886 - accuracy: 0.8273 - val_loss: 0.2832 - val_accuracy: 0.8951\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   zoom_range=0.3, rotation_range=50,\n",
    " width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
    " horizontal_flip=True, fill_mode=\"nearest\")\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=N_SPLIT,shuffle=True,random_state=42)\n",
    "j = 0\n",
    "for train_idx, val_idx in list(kfold.split(train_x,train_y)):\n",
    "    x_train_df = df.iloc[train_idx]\n",
    "    x_valid_df = df.iloc[val_idx]\n",
    "    j+=1\n",
    "\n",
    "\n",
    "    training_set = train_datagen.flow_from_dataframe(dataframe=x_train_df, directory=TRAIN_PATH,\n",
    "                                                 x_col=\"Image\", y_col=\"Class\",\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "    \n",
    "    validation_set = validation_datagen.flow_from_dataframe(dataframe=x_valid_df, directory=TRAIN_PATH,\n",
    "                                                 x_col=\"Image\", y_col=\"Class\",\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model_test = get_model(IMG_SIZE)\n",
    "    \n",
    "    \n",
    "    history = model_test.fit_generator( training_set,\n",
    "                                        validation_data=validation_set,\n",
    "                                        epochs = EPOCHS,\n",
    "                                        steps_per_epoch=x_train_df.shape[0] // BATCH_SIZE\n",
    "                                        )\n",
    "    \n",
    "    y_pred = []\n",
    "    name = []                      \n",
    "    labels = (training_set.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    for i in os.listdir('../input/hackerearth-deep-learning-challenge-holidayseason/dataset/test/'):\n",
    "        name.append(i)\n",
    "        i='../input/hackerearth-deep-learning-challenge-holidayseason/dataset/test/'+i\n",
    "        img=image.load_img(i,target_size=(IMG_SIZE,IMG_SIZE,3))\n",
    "        img=image.img_to_array(img)/255\n",
    "        pred=model_test.predict(img.reshape(1,IMG_SIZE,IMG_SIZE,3))\n",
    "        y_pred.append(labels[np.argmax(pred[0])])\n",
    "                                       \n",
    "    data_kfold[j] = y_pred\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in os.listdir('../input/hackerearth-deep-learning-challenge-holidayseason/dataset/test/'):\n",
    "    name.append(i)\n",
    "ans = pd.DataFrame(name,columns = ['Image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[\"Class\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking The Label with Maximum Occurences\n",
    "\n",
    "import collections \n",
    "for i in range(len(data_kfold)):\n",
    "    co = collections.Counter(data_kfold.loc[i])\n",
    "    \n",
    "    co = sorted(co.items(),key=lambda x: x[1],reverse=True)\n",
    "    ans.Class.loc[i] = co[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv('Kfold_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
